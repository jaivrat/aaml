{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "afb8c6bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "%config IPCompleter.greedy=True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a4295bb",
   "metadata": {},
   "source": [
    "Accuracy Score = (TP + TN) / (TP + TN + FP + FN)\n",
    "\n",
    "Precision = TP / (TP + FP)\n",
    "\n",
    "Recall = TP / (TP + FN)\n",
    "\n",
    "F1: It is defined as a simple weighted average (harmonic mean) of precision and recall.\n",
    "\n",
    "F1 = 2PR / (P + R)\n",
    "\n",
    "(Note that HM is close wo lower side of two numbers, not like AM which is in between)\n",
    "\n",
    "I better remeber these (as i use in ROC/AUC):\n",
    "\n",
    "*  ***TPR*** or True Positive Rate. Also called **Senstivity** = how many positive records correctly predicted? = TP/(TP+FN)\n",
    "\n",
    "* ***FPR*** or False Positive Rate. ***Specificity*** = 1 - FPR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "19d0f404",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5714285714285715"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "l1 = [0,1,1,1,0,0,0,1]\n",
    "l2 = [0,1,0,1,0,1,0,0]\n",
    "metrics.accuracy_score(l1, l2)\n",
    "metrics.f1_score(l1, l2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c48c4d85",
   "metadata": {},
   "source": [
    "AUC:\n",
    "\n",
    "* AUC = 1 => Perfect model\n",
    "\n",
    "* AUC = 0.5 => Random guess ..\n",
    "\n",
    "* AUC < 0.5 => Not possible. Just invert prediction - may be making some mistake\n",
    "\n",
    "LOG LOSS Metrics:\n",
    "\n",
    "Log Loss = - 1.0 * ( target * log(prediction) + (1 - target) * log(1 - prediction) )\n",
    "\n",
    "For multiple samples, obviously take average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3088a32b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.49882711861432294"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_true =  [0,     0,   0,   0,   1,    0,   1,   0,   0,    1,   0,   1,    0,    0,    1]\n",
    "y_proba = [0.1, 0.3, 0.2, 0.6, 0.8, 0.05, 0.9, 0.5, 0.3, 0.66, 0.3, 0.2, 0.85, 0.15, 0.99]\n",
    "metrics.log_loss(y_true, y_proba)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0dfe9e6",
   "metadata": {},
   "source": [
    "For multi-class classification, if we need to calc precision etc, \n",
    "\n",
    "\n",
    "**Macro averaged precision:** \n",
    "calculate precision for all classes individually and then average them\n",
    "\n",
    "**Micro averaged precision:**\n",
    "calculate class wise true positive and false positive and then use that to calculate overall precision\n",
    "\n",
    "**Weighted precision:**\n",
    "same as macro but in this case, it is weighted average depending on the number of items in each class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4f9baec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aaml",
   "language": "python",
   "name": "aaml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
