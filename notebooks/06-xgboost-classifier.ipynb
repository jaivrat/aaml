{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "286c7dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn import model_selection\n",
    "\n",
    "url = 'https://raw.githubusercontent.com/rabiibouhestine/Kaggle-cat-in-the-dat/master/train.csv'\n",
    "df = pd.read_csv(url)\n",
    "\n",
    "# we create a new column called kfold and fill it with -1\n",
    "df[\"kfold\"] = -1\n",
    "\n",
    "# the next step is to randomize the rows of the data\n",
    "df = df.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "# fetch labels\n",
    "y = df.target.values\n",
    "\n",
    "# initiate the kfold class from model_selection module\n",
    "kf = model_selection.StratifiedKFold(n_splits=5)\n",
    "\n",
    "# fill the new kfold column\n",
    "for f, (t_, v_) in enumerate(kf.split(X=df, y=y)):\n",
    "    df.loc[v_, 'kfold'] = f\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "18dfa4b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn import metrics\n",
    "from sklearn import preprocessing\n",
    "\n",
    "def run_xgboost_label_encoded(fold, data):\n",
    "    df = data.copy()\n",
    "    # load the full training data with folds\n",
    "    #df = pd.read_csv(url)\n",
    "\n",
    "    # all columns are features except id, target and kfold columns\n",
    "    features = [f for f in df.columns if f not in (\"id\", \"target\", \"kfold\")]\n",
    "\n",
    "    # fill all NaN values with NONE\n",
    "    # note that I am converting all columns to \"strings\"\n",
    "    # it doesn’t matter because all are categories\n",
    "    for col in features:\n",
    "        df.loc[:, col] = df[col].astype(str).fillna(\"NONE\")\n",
    "        \n",
    "    # now it’s time to label encode the features\n",
    "    for col in features:\n",
    "        # initialize LabelEncoder for each feature column\n",
    "        lbl = preprocessing.LabelEncoder()\n",
    "        # fit label encoder on all data\n",
    "        lbl.fit(df[col])\n",
    "        # transform all the data\n",
    "        df.loc[:, col] = lbl.transform(df[col])\n",
    "\n",
    "    # get training data using folds\n",
    "    df_train = df[df.kfold != fold].reset_index(drop=True)\n",
    "\n",
    "    # get validation data using folds\n",
    "    df_valid = df[df.kfold == fold].reset_index(drop=True)\n",
    "    \n",
    "    # get training data\n",
    "    x_train = df_train[features].values\n",
    "    # get validation data\n",
    "    x_valid = df_valid[features].values\n",
    "    \n",
    "    # initialize xgboost model\n",
    "    model = xgb.XGBClassifier(n_jobs=-1, max_depth=7, n_estimators=200)\n",
    "    \n",
    "    # fit model on training data\n",
    "    model.fit(x_train, df_train.target.values)\n",
    "\n",
    "    # predict on validation data\n",
    "    # we need the probability values as we are calculating AUC\n",
    "    # we will use the probability of 1s\n",
    "    valid_preds = model.predict_proba(x_valid)[:, 1]\n",
    "    \n",
    "    # get roc auc score\n",
    "    auc = metrics.roc_auc_score(df_valid.target.values, valid_preds)\n",
    "    \n",
    "    # print auc\n",
    "    print(f\"Fold = {fold}, AUC = {auc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dcd01310",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold = 0, AUC = 0.7651353896345039\n",
      "Fold = 1, AUC = 0.7693134854960211\n",
      "Fold = 2, AUC = 0.7663161657864546\n",
      "Fold = 3, AUC = 0.7655048207000421\n",
      "Fold = 4, AUC = 0.7680425346019139\n"
     ]
    }
   ],
   "source": [
    "for fold in range(5):\n",
    "    run_xgboost_label_encoded(fold, df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "438dc13f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install xgboost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e318aabc",
   "metadata": {},
   "source": [
    "Note xgboost modified  parameters a bit:\n",
    "\n",
    "* Default max_depth for xgboost is 3, and we use 7\n",
    "\n",
    "* the number of estimators (n_estimators) from 100 to 200."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eb982a1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aaml",
   "language": "python",
   "name": "aaml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
