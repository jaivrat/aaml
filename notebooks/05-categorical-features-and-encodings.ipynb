{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c6f85ea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d7f8e397",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://raw.githubusercontent.com/rabiibouhestine/Kaggle-cat-in-the-dat/master/train.csv'\n",
    "df = pd.read_csv(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5fe05e60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>bin_0</th>\n",
       "      <th>bin_1</th>\n",
       "      <th>bin_2</th>\n",
       "      <th>bin_3</th>\n",
       "      <th>bin_4</th>\n",
       "      <th>nom_0</th>\n",
       "      <th>nom_1</th>\n",
       "      <th>nom_2</th>\n",
       "      <th>nom_3</th>\n",
       "      <th>...</th>\n",
       "      <th>nom_9</th>\n",
       "      <th>ord_0</th>\n",
       "      <th>ord_1</th>\n",
       "      <th>ord_2</th>\n",
       "      <th>ord_3</th>\n",
       "      <th>ord_4</th>\n",
       "      <th>ord_5</th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>T</td>\n",
       "      <td>Y</td>\n",
       "      <td>Green</td>\n",
       "      <td>Triangle</td>\n",
       "      <td>Snake</td>\n",
       "      <td>Finland</td>\n",
       "      <td>...</td>\n",
       "      <td>2f4cb3d51</td>\n",
       "      <td>2</td>\n",
       "      <td>Grandmaster</td>\n",
       "      <td>Cold</td>\n",
       "      <td>h</td>\n",
       "      <td>D</td>\n",
       "      <td>kr</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>T</td>\n",
       "      <td>Y</td>\n",
       "      <td>Green</td>\n",
       "      <td>Trapezoid</td>\n",
       "      <td>Hamster</td>\n",
       "      <td>Russia</td>\n",
       "      <td>...</td>\n",
       "      <td>f83c56c21</td>\n",
       "      <td>1</td>\n",
       "      <td>Grandmaster</td>\n",
       "      <td>Hot</td>\n",
       "      <td>a</td>\n",
       "      <td>A</td>\n",
       "      <td>bF</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>F</td>\n",
       "      <td>Y</td>\n",
       "      <td>Blue</td>\n",
       "      <td>Trapezoid</td>\n",
       "      <td>Lion</td>\n",
       "      <td>Russia</td>\n",
       "      <td>...</td>\n",
       "      <td>ae6800dd0</td>\n",
       "      <td>1</td>\n",
       "      <td>Expert</td>\n",
       "      <td>Lava Hot</td>\n",
       "      <td>h</td>\n",
       "      <td>R</td>\n",
       "      <td>Jc</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>F</td>\n",
       "      <td>Y</td>\n",
       "      <td>Red</td>\n",
       "      <td>Trapezoid</td>\n",
       "      <td>Snake</td>\n",
       "      <td>Canada</td>\n",
       "      <td>...</td>\n",
       "      <td>8270f0d71</td>\n",
       "      <td>1</td>\n",
       "      <td>Grandmaster</td>\n",
       "      <td>Boiling Hot</td>\n",
       "      <td>i</td>\n",
       "      <td>D</td>\n",
       "      <td>kW</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>F</td>\n",
       "      <td>N</td>\n",
       "      <td>Red</td>\n",
       "      <td>Trapezoid</td>\n",
       "      <td>Lion</td>\n",
       "      <td>Canada</td>\n",
       "      <td>...</td>\n",
       "      <td>b164b72a7</td>\n",
       "      <td>1</td>\n",
       "      <td>Grandmaster</td>\n",
       "      <td>Freezing</td>\n",
       "      <td>a</td>\n",
       "      <td>R</td>\n",
       "      <td>qP</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  bin_0  bin_1  bin_2 bin_3 bin_4  nom_0      nom_1    nom_2    nom_3  \\\n",
       "0   0      0      0      0     T     Y  Green   Triangle    Snake  Finland   \n",
       "1   1      0      1      0     T     Y  Green  Trapezoid  Hamster   Russia   \n",
       "2   2      0      0      0     F     Y   Blue  Trapezoid     Lion   Russia   \n",
       "3   3      0      1      0     F     Y    Red  Trapezoid    Snake   Canada   \n",
       "4   4      0      0      0     F     N    Red  Trapezoid     Lion   Canada   \n",
       "\n",
       "   ...      nom_9 ord_0        ord_1        ord_2 ord_3 ord_4  ord_5 day  \\\n",
       "0  ...  2f4cb3d51     2  Grandmaster         Cold     h     D     kr   2   \n",
       "1  ...  f83c56c21     1  Grandmaster          Hot     a     A     bF   7   \n",
       "2  ...  ae6800dd0     1       Expert     Lava Hot     h     R     Jc   7   \n",
       "3  ...  8270f0d71     1  Grandmaster  Boiling Hot     i     D     kW   2   \n",
       "4  ...  b164b72a7     1  Grandmaster     Freezing     a     R     qP   7   \n",
       "\n",
       "  month target  \n",
       "0     2      0  \n",
       "1     8      0  \n",
       "2     2      0  \n",
       "3     1      1  \n",
       "4     8      0  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dfbc1d6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping = {\n",
    "\"Freezing\": 0,\n",
    "\"Warm\": 1,\n",
    "\"Cold\": 2,\n",
    "\"Boiling Hot\": 3,\n",
    "\"Hot\": 4,\n",
    "\"Lava Hot\": 5\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "81f963df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Freezing       99816\n",
       "Lava Hot       63908\n",
       "Boiling Hot    60627\n",
       "Cold           33768\n",
       "Hot            22227\n",
       "Warm           19654\n",
       "Name: ord_2, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Value counts before mapping:\n",
    "df.ord_2.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "89832c8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    99816\n",
       "5    63908\n",
       "3    60627\n",
       "2    33768\n",
       "4    22227\n",
       "1    19654\n",
       "Name: ord_2, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[[\"ord_2\"]] =  df.ord_2.map(mapping)\n",
    "\n",
    "# Value counts after mapping:\n",
    "df.ord_2.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37b4401c",
   "metadata": {},
   "source": [
    "This type of encoding of categorical variables is known as Label Encoding, i.e.,we are encoding every category as a numerical label.\n",
    "\n",
    "We can do the same by using LabelEncoder from scikit-learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d29184c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "# reat data\n",
    "url = 'https://raw.githubusercontent.com/rabiibouhestine/Kaggle-cat-in-the-dat/master/train.csv'\n",
    "df = pd.read_csv(url)\n",
    "\n",
    "# fill NaN values in ord_2 column\n",
    "df.loc[:, \"ord_2\"] = df.ord_2.fillna(\"NONE\")\n",
    "\n",
    "lbl_enc = preprocessing.LabelEncoder()\n",
    "\n",
    "# fit label encoder and transform values on ord_2 column\n",
    "# P.S: do not use this directly. fit first, then transform\n",
    "df.loc[:, \"ord_2\"] = lbl_enc.fit_transform(df.ord_2.values)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9964d3aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import sparse\n",
    "\n",
    "# create our example feature matrix\n",
    "example = np.array(\n",
    "                [\n",
    "                [0, 0, 1],\n",
    "                [1, 0, 0],\n",
    "                [1, 0, 1]\n",
    "                ])\n",
    "\n",
    "# convert numpy array to sparse CSR matrix\n",
    "sparse_example = sparse.csr_matrix(example)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2940777c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<3x3 sparse matrix of type '<class 'numpy.longlong'>'\n",
       "\twith 4 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sparse_example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4a618fd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'  (0, 2)\\t1\\n  (1, 0)\\t1\\n  (2, 0)\\t1\\n  (2, 2)\\t1'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(sparse_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a61a00b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of dense array: 8000000000\n",
      "Size of sparse array: 400009648\n",
      "Full size of sparse array: 600054476\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy import sparse\n",
    "\n",
    "\n",
    "# number of rows\n",
    "n_rows = 10000\n",
    "# number of columns\n",
    "n_cols = 100000\n",
    "\n",
    "# create random binary matrix with only 5% values as 1s\n",
    "example = np.random.binomial(1, p=0.05, size=(n_rows, n_cols))\n",
    "\n",
    "# print size in bytes\n",
    "print(f\"Size of dense array: {example.nbytes}\")\n",
    "# convert numpy array to sparse CSR matrix\n",
    "sparse_example = sparse.csr_matrix(example)\n",
    "# print size of this sparse matrix\n",
    "print(f\"Size of sparse array: {sparse_example.data.nbytes}\")\n",
    "full_size = (\n",
    "sparse_example.data.nbytes +\n",
    "sparse_example.indptr.nbytes +\n",
    "sparse_example.indices.nbytes\n",
    ")\n",
    "# print full size of this sparse matrix\n",
    "print(f\"Full size of sparse array: {full_size}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8fd4beda",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"new_feature\"] = (df.ord_1.astype(str) + \"_\" + df.ord_2.astype(str))\n",
    "df[\"new_feature\"] = (df.ord_1.astype(str) + \"_\" + df.ord_2.astype(str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "db372c22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         Grandmaster_1\n",
       "1         Grandmaster_3\n",
       "2              Expert_4\n",
       "3         Grandmaster_0\n",
       "4         Grandmaster_2\n",
       "              ...      \n",
       "299995    Contributor_2\n",
       "299996         Novice_2\n",
       "299997         Novice_0\n",
       "299998         Master_0\n",
       "299999    Contributor_2\n",
       "Name: new_feature, Length: 300000, dtype: object"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.new_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ae38cd7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.ord_4 = df.ord_4.fillna(\"NONE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5a5c3b27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We say that wherever the value count for a certain category is less than 2000, replace it with rare.\n",
    "# For binary classification, it might be skewed traget - use StratifiedKFold later\n",
    "df.loc[ df[\"ord_4\"].value_counts()[df[\"ord_4\"]].values < 2000, \"ord_4\"] = \"RARE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d685d4ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b18f5a01",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import model_selection\n",
    "\n",
    "df = pd.read_csv(url)\n",
    "\n",
    "# we create a new column called kfold and fill it with -1\n",
    "df[\"kfold\"] = -1\n",
    "\n",
    "# the next step is to randomize the rows of the data\n",
    "df = df.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "# fetch labels\n",
    "y = df.target.values\n",
    "\n",
    "# initiate the kfold class from model_selection module\n",
    "kf = model_selection.StratifiedKFold(n_splits=5)\n",
    "\n",
    "# fill the new kfold column\n",
    "for f, (t_, v_) in enumerate(kf.split(X=df, y=y)):\n",
    "    df.loc[v_, 'kfold'] = f\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "732b7617",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "150f732c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ohe_logres.py\n",
    "import pandas as pd\n",
    "from sklearn import linear_model\n",
    "from sklearn import metrics\n",
    "from sklearn import preprocessing\n",
    "\n",
    "def run(fold, data):\n",
    "    df = data.copy()\n",
    "    # load the full training data with folds\n",
    "    #df = pd.read_csv(url)\n",
    "\n",
    "    # all columns are features except id, target and kfold columns\n",
    "    features = [f for f in df.columns if f not in (\"id\", \"target\", \"kfold\")]\n",
    "\n",
    "    # fill all NaN values with NONE\n",
    "    # note that I am converting all columns to \"strings\"\n",
    "    # it doesnâ€™t matter because all are categories\n",
    "    for col in features:\n",
    "        df.loc[:, col] = df[col].astype(str).fillna(\"NONE\")\n",
    "\n",
    "    # get training data using folds\n",
    "    df_train = df[df.kfold != fold].reset_index(drop=True)\n",
    "\n",
    "    # get validation data using folds\n",
    "    df_valid = df[df.kfold == fold].reset_index(drop=True)\n",
    "\n",
    "    # initialize OneHotEncoder from scikit-learn\n",
    "    ohe = preprocessing.OneHotEncoder()\n",
    "\n",
    "    # fit ohe on training + validation features\n",
    "    full_data = pd.concat([df_train[features], df_valid[features]],axis=0)\n",
    "    \n",
    "    ohe.fit(full_data[features])\n",
    "    \n",
    "    # transform training data\n",
    "    x_train = ohe.transform(df_train[features])\n",
    "    \n",
    "    # transform validation data\n",
    "    x_valid = ohe.transform(df_valid[features])\n",
    "    \n",
    "    # initialize Logistic Regression model\n",
    "    model = linear_model.LogisticRegression()\n",
    "    \n",
    "    # fit model on training data (ohe)\n",
    "    model.fit(x_train, df_train.target.values)\n",
    "\n",
    "    # predict on validation data\n",
    "    # we need the probability values as we are calculating AUC\n",
    "    # we will use the probability of 1s\n",
    "    valid_preds = model.predict_proba(x_valid)[:, 1]\n",
    "\n",
    "    # get roc auc score\n",
    "    auc = metrics.roc_auc_score(df_valid.target.values, valid_preds)\n",
    "    \n",
    "    # print auc\n",
    "    print(f\"Fold = {fold}, AUC = {auc}\")\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "60572e92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold = 0, AUC = 0.7966309072113826\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jvsingh/anaconda3/envs/aaml/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "# run function for fold = 0\n",
    "# we can just replace this number and\n",
    "# run this for any fold\n",
    "run(0,df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "de9d3222",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jvsingh/anaconda3/envs/aaml/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold = 0, AUC = 0.7966309072113826\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jvsingh/anaconda3/envs/aaml/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold = 1, AUC = 0.7984243305934173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jvsingh/anaconda3/envs/aaml/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold = 2, AUC = 0.7998085833722692\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jvsingh/anaconda3/envs/aaml/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold = 3, AUC = 0.797120146119528\n",
      "Fold = 4, AUC = 0.7924881907525214\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jvsingh/anaconda3/envs/aaml/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "for fold_ in range(5):\n",
    "    run(fold_, df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64e09212",
   "metadata": {},
   "source": [
    "AUC seems stable.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "789e2471",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 2 0 0 1 0 0 0 0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jvsingh/anaconda3/envs/aaml/lib/python3.7/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>orig</th>\n",
       "      <th>new</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aa</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aa</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>xyz</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>aa</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>aa</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>alpha</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>aa</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>aa</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>aa</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>aa</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    orig  new\n",
       "0     aa    0\n",
       "1     aa    0\n",
       "2    xyz    2\n",
       "3     aa    0\n",
       "4     aa    0\n",
       "5  alpha    1\n",
       "6     aa    0\n",
       "7     aa    0\n",
       "8     aa    0\n",
       "9     aa    0"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Demo LabelEncoder\n",
    "lbl = preprocessing.LabelEncoder()\n",
    "vals = np.random.choice(['aa', 'alpha', 'b', 'xyz'],  size=10, replace=True, p=None).reshape(-1,1)\n",
    "lbl.fit(vals)\n",
    "trs = lbl.transform(vals)\n",
    "print(trs)\n",
    "pd.DataFrame({'orig':vals.reshape(-1), 'new': trs})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "5d28ff59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random forest\n",
    "from sklearn import ensemble\n",
    "\n",
    "def run_rf(fold, data):\n",
    "    df = data.copy()\n",
    "    # load the full training data with folds\n",
    "    #df = pd.read_csv(url)\n",
    "\n",
    "    # all columns are features except id, target and kfold columns\n",
    "    features = [f for f in df.columns if f not in (\"id\", \"target\", \"kfold\")]\n",
    "\n",
    "    # fill all NaN values with NONE\n",
    "    # note that I am converting all columns to \"strings\"\n",
    "    # it doesnâ€™t matter because all are categories\n",
    "    for col in features:\n",
    "        df.loc[:, col] = df[col].astype(str).fillna(\"NONE\")\n",
    "        \n",
    "    # now its time to label encode the features\n",
    "    for col in features:\n",
    "        lbl = preprocessing.LabelEncoder()\n",
    "        # fit label encoder on all data\n",
    "        lbl.fit(df[col])\n",
    "        # transform all the data\n",
    "        df.loc[:, col] = lbl.transform(df[col])\n",
    "        \n",
    "\n",
    "    # get training data using folds\n",
    "    df_train = df[df.kfold != fold].reset_index(drop=True)\n",
    "\n",
    "    # get validation data using folds\n",
    "    df_valid = df[df.kfold == fold].reset_index(drop=True)\n",
    "\n",
    "    # initialize OneHotEncoder from scikit-learn\n",
    "    #ohe = preprocessing.OneHotEncoder()\n",
    "    # fit ohe on training + validation features\n",
    "    #full_data = pd.concat([df_train[features], df_valid[features]],axis=0)\n",
    "    #\n",
    "    #ohe.fit(full_data[features])\n",
    "    \n",
    "    # transform training data\n",
    "    x_train = df_train[features].values\n",
    "    \n",
    "    # transform validation data\n",
    "    x_valid = df_valid[features].values\n",
    "    \n",
    "    # initialize  model\n",
    "    model = ensemble.RandomForestClassifier(n_jobs=-1)\n",
    "    \n",
    "    # fit model on training data (ohe)\n",
    "    model.fit(x_train, df_train.target.values)\n",
    "\n",
    "    # predict on validation data\n",
    "    # we need the probability values as we are calculating AUC\n",
    "    # we will use the probability of 1s\n",
    "    valid_preds = model.predict_proba(x_valid)[:, 1]\n",
    "\n",
    "    # get roc auc score\n",
    "    auc = metrics.roc_auc_score(df_valid.target.values, valid_preds)\n",
    "    \n",
    "    # print auc\n",
    "    print(f\"Fold = {fold}, AUC = {auc}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "061cdef0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold = 0, AUC = 0.7333673698545807\n",
      "Fold = 1, AUC = 0.732662072369133\n",
      "Fold = 2, AUC = 0.737999543325451\n",
      "Fold = 3, AUC = 0.7355850907849831\n",
      "Fold = 4, AUC = 0.7353569438689953\n"
     ]
    }
   ],
   "source": [
    "from sklearn import model_selection\n",
    "\n",
    "df = pd.read_csv(url)\n",
    "\n",
    "# we create a new column called kfold and fill it with -1\n",
    "df[\"kfold\"] = -1\n",
    "\n",
    "# the next step is to randomize the rows of the data\n",
    "df = df.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "# fetch labels\n",
    "y = df.target.values\n",
    "\n",
    "# initiate the kfold class from model_selection module\n",
    "kf = model_selection.StratifiedKFold(n_splits=5)\n",
    "\n",
    "# fill the new kfold column\n",
    "for f, (t_, v_) in enumerate(kf.split(X=df, y=y)):\n",
    "    df.loc[v_, 'kfold'] = f\n",
    "    \n",
    "    \n",
    "for fold_ in range(5):\n",
    "    run_rf(fold_, df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8529e7e",
   "metadata": {},
   "source": [
    "The random forest model, without any tuning of hyperparameters, performs a lot worse than simple logistic regression. => Start with simple model first.\n",
    "\n",
    "Also I saw random forest was slow and definintely more space consuming."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a162a2a2",
   "metadata": {},
   "source": [
    "## SVD based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "1d8d2091",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import model_selection\n",
    "\n",
    "df = pd.read_csv(url)\n",
    "\n",
    "# we create a new column called kfold and fill it with -1\n",
    "df[\"kfold\"] = -1\n",
    "\n",
    "# the next step is to randomize the rows of the data\n",
    "df = df.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "# fetch labels\n",
    "y = df.target.values\n",
    "\n",
    "# initiate the kfold class from model_selection module\n",
    "kf = model_selection.StratifiedKFold(n_splits=5)\n",
    "\n",
    "# fill the new kfold column\n",
    "for f, (t_, v_) in enumerate(kf.split(X=df, y=y)):\n",
    "    df.loc[v_, 'kfold'] = f\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16b3ad13",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import decomposition\n",
    "from sklearn import metrics\n",
    "from sklearn import preprocessing\n",
    "from sklearn import ensemble\n",
    "from scipy import sparse\n",
    "\n",
    "def run_rf_svdtruncated(fold, data):\n",
    "    df = data.copy()\n",
    "    # load the full training data with folds\n",
    "    #df = pd.read_csv(url)\n",
    "\n",
    "    # all columns are features except id, target and kfold columns\n",
    "    features = [f for f in df.columns if f not in (\"id\", \"target\", \"kfold\")]\n",
    "\n",
    "    # fill all NaN values with NONE\n",
    "    # note that I am converting all columns to \"strings\"\n",
    "    # it doesnâ€™t matter because all are categories\n",
    "    for col in features:\n",
    "        df.loc[:, col] = df[col].astype(str).fillna(\"NONE\")\n",
    "\n",
    "    # get training data using folds\n",
    "    df_train = df[df.kfold != fold].reset_index(drop=True)\n",
    "\n",
    "    # get validation data using folds\n",
    "    df_valid = df[df.kfold == fold].reset_index(drop=True)\n",
    "    \n",
    "    \n",
    "    # initialize OneHotEncoder from scikit-learn\n",
    "    ohe = preprocessing.OneHotEncoder()\n",
    "    # fit ohe on training + validation features\n",
    "    full_data = pd.concat([df_train[features], df_valid[features]],axis=0)\n",
    "    ohe.fit(full_data[features])\n",
    "    \n",
    "    # transform training data\n",
    "    x_train = ohe.transform(df_train[features])\n",
    "    \n",
    "    # transform validation data\n",
    "    x_valid = ohe.transform(df_valid[features])\n",
    "    \n",
    "    # initialize Truncated SVD\n",
    "    # we are reducing the data to 120 components\n",
    "    svd = decomposition.TruncatedSVD(n_components=120)\n",
    "\n",
    "    # fit svd on full sparse training data\n",
    "    full_sparse = sparse.vstack((x_train, x_valid))\n",
    "    svd.fit(full_sparse)\n",
    "\n",
    "    # transform sparse training data\n",
    "    x_train = svd.transform(x_train)\n",
    "    # transform sparse validation data\n",
    "    x_valid = svd.transform(x_valid)\n",
    "\n",
    "    # initialize  model\n",
    "    model = ensemble.RandomForestClassifier(n_jobs=-1)\n",
    "    \n",
    "    # fit model on training data (ohe)\n",
    "    model.fit(x_train, df_train.target.values)\n",
    "\n",
    "    # fit model on training data (ohe)\n",
    "    model.fit(x_train, df_train.target.values)\n",
    "    # predict on validation data\n",
    "    # we need the probability values as we are calculating AUC\n",
    "    # we will use the probability of 1s\n",
    "    valid_preds = model.predict_proba(x_valid)[:, 1]\n",
    "    # get roc auc score\n",
    "    auc = metrics.roc_auc_score(df_valid.target.values, valid_preds)\n",
    "    # print auc\n",
    "    return(f\"Fold = {fold}, AUC = {auc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "431d70cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TIME taking - so we run in parallel\n",
    "#for fold in range(5):\n",
    "#    run_rf_svdtruncated(fold, df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7ecd04f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-25 22:23:29,877\tINFO worker.py:1642 -- Started a local Ray instance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import ray\n",
    "\n",
    "@ray.remote\n",
    "def run_rf_svdtruncated_remote(fold, data):\n",
    "    return run_rf_svdtruncated(fold, data)\n",
    "    \n",
    "context = ray.init()\n",
    "print(context.dashboard_url)\n",
    "\n",
    "results = []\n",
    "for fold in range(5):\n",
    "    results.append(run_rf_svdtruncated_remote.remote(fold, df))\n",
    "   \n",
    "rs = ray.get(results)  # [0, 1, 2, 3]\n",
    "\n",
    "for r in results:\n",
    "    print(r)\n",
    "    \n",
    "ray.shutdown()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "ff10d64b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "572d765b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aaml",
   "language": "python",
   "name": "aaml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
